{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f94fafd-b97f-4583-8b25-3227be3dab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FastChat'...\n",
      "remote: Enumerating objects: 5847, done.\u001b[K\n",
      "remote: Counting objects: 100% (2092/2092), done.\u001b[K\n",
      "remote: Compressing objects: 100% (323/323), done.\u001b[K\n",
      "remote: Total 5847 (delta 1949), reused 1815 (delta 1768), pack-reused 3755\u001b[K\n",
      "Receiving objects: 100% (5847/5847), 31.86 MiB | 53.48 MiB/s, done.\n",
      "Resolving deltas: 100% (4338/4338), done.\n",
      "Obtaining file:///workspace/FastChat\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: fschat 0.2.36 does not provide the extra 'llm-judge'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: fschat 0.2.36 does not provide the extra 'model-worker'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting markdown2[all]\n",
      "  Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting nh3\n",
      "  Downloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (3.0.39)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
      "Collecting rich>=10.0.0\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shortuuid\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openai<1\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting anthropic>=0.3\n",
      "  Downloading anthropic-0.16.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ray\n",
      "  Downloading ray-2.9.3-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting accelerate>=0.21\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Collecting transformers>=4.31.0\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21) (6.0.1)\n",
      "Collecting huggingface-hub (from accelerate>=0.21)\n",
      "  Downloading huggingface_hub-0.21.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate>=0.21)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.3) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic>=0.3) (1.7.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic>=0.3) (1.3.0)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic>=0.3)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from anthropic>=0.3)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.4)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting tqdm (from openai<1)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0) (0.2.9)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic)\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.13)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.0.0)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0) (2.16.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.31.0)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting wavedrom (from markdown2[all])\n",
      "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting click>=7.0 (from ray)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray)\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic>=0.3) (1.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.0.0)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all])\n",
      "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from wavedrom->markdown2[all]) (1.16.0)\n",
      "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.16.0-py3-none-any.whl (846 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.4/846.4 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m184.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.9.3-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.1-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.1/346.1 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fschat, wavedrom\n",
      "  Building editable for fschat (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fschat: filename=fschat-0.2.36-0.editable-py3-none-any.whl size=14311 sha256=8a15430d58be9d6f5892223ed4dc79108fa875dcd452746664b85d154913fa6d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-14rubs7f/wheels/49/a8/18/7e45d95e85005d650fb59897c5c7fa87f2597602aec43d4558\n",
      "  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30053 sha256=760272b9a4d7dd8639d9d6ab3e40d5fd0f577c7fd17883a0af72843b3c969458\n",
      "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
      "Successfully built fschat wavedrom\n",
      "Installing collected packages: sentencepiece, nh3, typing-extensions, tqdm, svgwrite, shortuuid, safetensors, regex, protobuf, multidict, msgpack, mdurl, markdown2, h11, fsspec, frozenlist, click, async-timeout, annotated-types, yarl, wavedrom, uvicorn, tiktoken, starlette, pydantic-core, markdown-it-py, huggingface-hub, httpcore, aiosignal, tokenizers, rich, pydantic, httpx, aiohttp, accelerate, transformers, ray, openai, fastapi, anthropic, peft, fschat\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.27.2 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anthropic-0.16.0 async-timeout-4.0.3 click-8.1.7 fastapi-0.110.0 frozenlist-1.4.1 fschat-0.2.36 fsspec-2024.2.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 huggingface-hub-0.21.1 markdown-it-py-3.0.0 markdown2-2.4.13 mdurl-0.1.2 msgpack-1.0.7 multidict-6.0.5 nh3-0.2.15 openai-0.28.1 peft-0.8.2 protobuf-4.25.3 pydantic-2.6.3 pydantic-core-2.16.3 ray-2.9.3 regex-2023.12.25 rich-13.7.0 safetensors-0.4.2 sentencepiece-0.2.0 shortuuid-1.0.11 starlette-0.36.3 svgwrite-1.4.3 tiktoken-0.6.0 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.38.1 typing-extensions-4.10.0 uvicorn-0.27.1 wavedrom-2.0.3.post3 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tabulate, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 tabulate-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Clone main branch of FastChat\n",
    "!git clone https://github.com/philschmid/FastChat.git\n",
    "# Install FastChat with model worker and llm_judge dependencies\n",
    "!pip install -e \"./FastChat[model_worker,llm_judge]\"\n",
    "!pip install matplotlib tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1d7246-7620-473c-af57-a9fdfe3af472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/FastChat/fastchat/llm_judge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd {os.getcwd()}/FastChat/fastchat/llm_judge\n",
    "# should be in FastChat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a85649-e646-4a15-a8f3-89380108b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output to data/mt_bench/model_answer/mistral-dolphin-sft.jsonl\n",
      "tokenizer_config.json: 100%|███████████████| 1.69k/1.69k [00:00<00:00, 6.38MB/s]\n",
      "tokenizer.model: 100%|████████████████████████| 493k/493k [00:00<00:00, 125MB/s]\n",
      "added_tokens.json: 100%|██████████████████████| 51.0/51.0 [00:00<00:00, 204kB/s]\n",
      "special_tokens_map.json: 100%|██████████████████| 100/100 [00:00<00:00, 412kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|█████████████████████████████| 622/622 [00:00<00:00, 2.61MB/s]\n",
      "pytorch_model.bin.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 55.3MB/s]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
      "pytorch_model-00001-of-00002.bin:   0%|             | 0.00/9.94G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 10.5M/9.94G [00:00<01:57, 84.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 21.0M/9.94G [00:00<03:41, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 31.5M/9.94G [00:00<03:35, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|    | 41.9M/9.94G [00:00<03:25, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 52.4M/9.94G [00:01<04:23, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 62.9M/9.94G [00:01<03:53, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 73.4M/9.94G [00:01<03:41, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 83.9M/9.94G [00:02<05:09, 31.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 94.4M/9.94G [00:02<04:24, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 105M/9.94G [00:02<04:50, 33.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 115M/9.94G [00:03<04:52, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 136M/9.94G [00:03<03:47, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 147M/9.94G [00:03<03:52, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 168M/9.94G [00:03<03:07, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 178M/9.94G [00:04<03:37, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 199M/9.94G [00:04<03:29, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 210M/9.94G [00:05<03:55, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 231M/9.94G [00:05<03:01, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 241M/9.94G [00:05<03:17, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 262M/9.94G [00:05<03:08, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 273M/9.94G [00:06<03:33, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 294M/9.94G [00:06<03:09, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 304M/9.94G [00:06<03:49, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 325M/9.94G [00:07<03:15, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 336M/9.94G [00:07<03:01, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 346M/9.94G [00:07<03:45, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 357M/9.94G [00:08<04:36, 34.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 367M/9.94G [00:08<03:54, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 377M/9.94G [00:08<03:42, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 388M/9.94G [00:09<04:19, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 409M/9.94G [00:09<04:07, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 419M/9.94G [00:10<05:11, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 440M/9.94G [00:10<03:55, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 451M/9.94G [00:10<04:24, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 472M/9.94G [00:11<04:06, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 482M/9.94G [00:11<04:01, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 503M/9.94G [00:12<04:07, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 514M/9.94G [00:12<04:02, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 535M/9.94G [00:12<03:39, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 545M/9.94G [00:13<04:04, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 556M/9.94G [00:13<03:35, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 566M/9.94G [00:13<03:41, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 577M/9.94G [00:13<04:28, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 598M/9.94G [00:14<03:45, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 608M/9.94G [00:14<04:08, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 629M/9.94G [00:15<03:47, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 640M/9.94G [00:15<03:20, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 650M/9.94G [00:15<03:09, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 661M/9.94G [00:15<03:59, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 682M/9.94G [00:16<03:14, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 692M/9.94G [00:16<03:57, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 703M/9.94G [00:16<03:31, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 713M/9.94G [00:16<03:15, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 724M/9.94G [00:17<04:16, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 744M/9.94G [00:17<03:08, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 755M/9.94G [00:18<03:44, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 776M/9.94G [00:18<03:45, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 786M/9.94G [00:18<03:54, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 797M/9.94G [00:18<03:19, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 807M/9.94G [00:19<03:24, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 818M/9.94G [00:19<04:05, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 839M/9.94G [00:19<03:15, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 849M/9.94G [00:20<03:41, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 860M/9.94G [00:20<03:39, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 870M/9.94G [00:20<03:41, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 881M/9.94G [00:21<03:37, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 902M/9.94G [00:21<03:11, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 912M/9.94G [00:21<03:59, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 923M/9.94G [00:21<03:20, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 933M/9.94G [00:22<03:43, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 944M/9.94G [00:22<03:21, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 954M/9.94G [00:22<03:09, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 965M/9.94G [00:22<03:02, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 986M/9.94G [00:23<02:33, 58.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▌    | 996M/9.94G [00:23<02:42, 55.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.02G/9.94G [00:23<02:57, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.03G/9.94G [00:24<03:16, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.05G/9.94G [00:24<03:04, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.06G/9.94G [00:25<03:53, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.08G/9.94G [00:25<03:22, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.09G/9.94G [00:25<03:51, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.11G/9.94G [00:26<03:56, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.12G/9.94G [00:26<04:00, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.13G/9.94G [00:27<04:18, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.14G/9.94G [00:27<03:50, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.15G/9.94G [00:27<03:29, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.17G/9.94G [00:27<03:21, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.18G/9.94G [00:28<03:14, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.21G/9.94G [00:28<02:47, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.22G/9.94G [00:28<03:29, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.24G/9.94G [00:29<03:16, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.25G/9.94G [00:29<03:18, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.26G/9.94G [00:29<03:12, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.27G/9.94G [00:30<03:43, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.28G/9.94G [00:30<03:18, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.29G/9.94G [00:30<03:23, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.30G/9.94G [00:30<03:41, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.32G/9.94G [00:31<03:00, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.33G/9.94G [00:31<03:53, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.34G/9.94G [00:31<03:16, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.35G/9.94G [00:31<03:13, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.36G/9.94G [00:32<03:11, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.38G/9.94G [00:32<02:57, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.39G/9.94G [00:32<03:39, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.42G/9.94G [00:33<03:24, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.43G/9.94G [00:33<03:47, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.45G/9.94G [00:34<03:12, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.46G/9.94G [00:34<03:53, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.48G/9.94G [00:35<03:49, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.49G/9.94G [00:35<03:59, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.51G/9.94G [00:36<03:46, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.52G/9.94G [00:36<04:42, 29.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▌   | 1.54G/9.94G [00:36<03:43, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▌   | 1.55G/9.94G [00:37<03:32, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.56G/9.94G [00:37<03:18, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.57G/9.94G [00:37<03:29, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.58G/9.94G [00:38<03:47, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.59G/9.94G [00:38<04:12, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.60G/9.94G [00:38<03:49, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.61G/9.94G [00:38<03:32, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.63G/9.94G [00:39<03:41, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.64G/9.94G [00:39<03:27, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.66G/9.94G [00:39<02:53, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.67G/9.94G [00:39<02:48, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.69G/9.94G [00:40<03:01, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.70G/9.94G [00:40<03:48, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.72G/9.94G [00:41<03:18, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.73G/9.94G [00:41<03:06, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.75G/9.94G [00:41<02:43, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.76G/9.94G [00:42<02:57, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.77G/9.94G [00:42<02:57, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.79G/9.94G [00:42<02:21, 57.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.81G/9.94G [00:42<02:15, 60.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.82G/9.94G [00:43<02:26, 55.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.85G/9.94G [00:43<02:30, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.86G/9.94G [00:43<02:37, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.87G/9.94G [00:44<02:45, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.88G/9.94G [00:44<02:59, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.89G/9.94G [00:44<02:51, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.90G/9.94G [00:44<02:55, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.91G/9.94G [00:45<03:18, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.93G/9.94G [00:45<02:56, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.94G/9.94G [00:45<03:12, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.96G/9.94G [00:46<02:27, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.97G/9.94G [00:46<02:25, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.99G/9.94G [00:46<02:17, 58.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.00G/9.94G [00:46<02:49, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.02G/9.94G [00:47<02:38, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.03G/9.94G [00:47<03:04, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.04G/9.94G [00:47<03:00, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.06G/9.94G [00:48<02:53, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.07G/9.94G [00:48<03:20, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.09G/9.94G [00:48<02:46, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.10G/9.94G [00:49<02:54, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.12G/9.94G [00:49<02:53, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.13G/9.94G [00:49<03:26, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.15G/9.94G [00:50<03:10, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.16G/9.94G [00:50<03:03, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.17G/9.94G [00:50<02:41, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.18G/9.94G [00:51<03:41, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.19G/9.94G [00:51<04:10, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.20G/9.94G [00:51<03:40, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.21G/9.94G [00:52<03:36, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.23G/9.94G [00:52<03:00, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.24G/9.94G [00:52<02:46, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.25G/9.94G [00:53<02:51, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.26G/9.94G [00:53<03:06, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.28G/9.94G [00:53<02:57, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.29G/9.94G [00:53<02:42, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.30G/9.94G [00:54<04:05, 31.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.31G/9.94G [00:54<03:38, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.33G/9.94G [00:54<03:06, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.34G/9.94G [00:55<02:56, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.36G/9.94G [00:55<03:01, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.37G/9.94G [00:56<03:16, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.39G/9.94G [00:56<02:54, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.40G/9.94G [00:56<03:07, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.42G/9.94G [00:57<02:51, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.43G/9.94G [00:57<02:54, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.45G/9.94G [00:57<02:48, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.46G/9.94G [00:58<03:05, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.49G/9.94G [00:58<02:32, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.50G/9.94G [00:58<02:17, 54.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.51G/9.94G [00:58<02:33, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.52G/9.94G [00:59<02:58, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.53G/9.94G [00:59<02:38, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.54G/9.94G [00:59<02:27, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.55G/9.94G [00:59<02:57, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.56G/9.94G [01:00<02:42, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.57G/9.94G [01:00<02:29, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.58G/9.94G [01:00<03:08, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.60G/9.94G [01:01<02:47, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.61G/9.94G [01:01<03:04, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.63G/9.94G [01:01<02:40, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.64G/9.94G [01:02<02:43, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.66G/9.94G [01:02<02:37, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.67G/9.94G [01:02<02:54, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.69G/9.94G [01:03<02:41, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.71G/9.94G [01:03<03:30, 34.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.73G/9.94G [01:04<02:53, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.74G/9.94G [01:04<02:50, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.76G/9.94G [01:04<02:24, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.77G/9.94G [01:05<03:04, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.79G/9.94G [01:05<02:57, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.80G/9.94G [01:05<02:36, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.81G/9.94G [01:05<02:27, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.82G/9.94G [01:06<02:50, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.84G/9.94G [01:06<02:34, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.85G/9.94G [01:07<03:00, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.87G/9.94G [01:07<02:24, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.88G/9.94G [01:07<02:47, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.90G/9.94G [01:08<02:42, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.92G/9.94G [01:08<02:52, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.94G/9.94G [01:08<02:38, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.95G/9.94G [01:09<02:42, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.97G/9.94G [01:09<02:45, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.98G/9.94G [01:09<02:45, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.00G/9.94G [01:10<02:49, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.01G/9.94G [01:10<02:52, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.03G/9.94G [01:11<02:52, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.04G/9.94G [01:11<02:45, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.06G/9.94G [01:11<02:41, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.07G/9.94G [01:12<02:32, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.09G/9.94G [01:12<02:33, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.10G/9.94G [01:12<02:18, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.11G/9.94G [01:13<02:54, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.12G/9.94G [01:13<02:53, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.15G/9.94G [01:13<02:48, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.16G/9.94G [01:14<03:19, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.18G/9.94G [01:14<02:40, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.19G/9.94G [01:15<02:49, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.21G/9.94G [01:15<02:33, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.22G/9.94G [01:15<03:01, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.23G/9.94G [01:16<02:40, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.24G/9.94G [01:16<02:41, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.25G/9.94G [01:16<02:33, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.27G/9.94G [01:17<02:35, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.28G/9.94G [01:17<02:54, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.30G/9.94G [01:17<02:20, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.31G/9.94G [01:18<02:49, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.33G/9.94G [01:18<02:22, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.34G/9.94G [01:19<03:18, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.37G/9.94G [01:19<02:41, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.38G/9.94G [01:19<02:44, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.40G/9.94G [01:20<02:22, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.41G/9.94G [01:20<02:12, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▍  | 3.42G/9.94G [01:20<02:08, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▍  | 3.43G/9.94G [01:20<02:07, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.45G/9.94G [01:20<01:59, 54.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.46G/9.94G [01:21<02:16, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.48G/9.94G [01:21<02:10, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.49G/9.94G [01:21<02:21, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.51G/9.94G [01:22<02:15, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.52G/9.94G [01:22<02:40, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.54G/9.94G [01:22<02:05, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.55G/9.94G [01:23<02:07, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.57G/9.94G [01:23<01:54, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.58G/9.94G [01:23<01:52, 56.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.59G/9.94G [01:23<01:56, 54.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.61G/9.94G [01:24<01:58, 53.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.62G/9.94G [01:24<02:01, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.64G/9.94G [01:24<02:00, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.65G/9.94G [01:24<02:04, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.67G/9.94G [01:25<01:49, 57.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.68G/9.94G [01:25<02:19, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.70G/9.94G [01:26<02:25, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.71G/9.94G [01:26<02:09, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.72G/9.94G [01:26<02:04, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.73G/9.94G [01:26<02:13, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.74G/9.94G [01:26<02:09, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.75G/9.94G [01:27<02:03, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.76G/9.94G [01:27<02:09, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.77G/9.94G [01:27<02:04, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.79G/9.94G [01:27<02:00, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.80G/9.94G [01:28<02:22, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.81G/9.94G [01:28<02:24, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.82G/9.94G [01:28<02:26, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.83G/9.94G [01:28<02:18, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.84G/9.94G [01:28<01:55, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.85G/9.94G [01:29<02:26, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.86G/9.94G [01:29<03:10, 32.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.88G/9.94G [01:30<02:47, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.89G/9.94G [01:30<02:19, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.91G/9.94G [01:30<02:12, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.92G/9.94G [01:31<02:24, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.94G/9.94G [01:31<02:13, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.95G/9.94G [01:31<02:39, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.97G/9.94G [01:32<02:15, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.98G/9.94G [01:32<02:30, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.00G/9.94G [01:32<02:17, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.01G/9.94G [01:33<02:46, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.02G/9.94G [01:33<02:51, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▌  | 4.04G/9.94G [01:34<02:31, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.06G/9.94G [01:34<02:15, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.07G/9.94G [01:34<02:15, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.09G/9.94G [01:35<02:34, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.10G/9.94G [01:35<02:27, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.12G/9.94G [01:35<02:03, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.13G/9.94G [01:36<02:05, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.15G/9.94G [01:36<01:55, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.16G/9.94G [01:36<02:27, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.17G/9.94G [01:37<02:11, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.18G/9.94G [01:37<02:24, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.19G/9.94G [01:37<02:39, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.22G/9.94G [01:38<02:29, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.23G/9.94G [01:38<02:34, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.25G/9.94G [01:39<02:28, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.26G/9.94G [01:39<02:29, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.27G/9.94G [01:39<02:30, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.28G/9.94G [01:39<02:24, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.29G/9.94G [01:40<02:39, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.31G/9.94G [01:40<02:18, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.32G/9.94G [01:40<02:13, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▋  | 4.34G/9.94G [01:41<01:57, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.35G/9.94G [01:41<02:04, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.36G/9.94G [01:41<02:02, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.37G/9.94G [01:42<01:57, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.39G/9.94G [01:42<01:42, 54.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.40G/9.94G [01:42<02:18, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.42G/9.94G [01:43<01:57, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.44G/9.94G [01:43<02:20, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.46G/9.94G [01:43<01:53, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.47G/9.94G [01:44<02:23, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.49G/9.94G [01:44<02:02, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.50G/9.94G [01:45<02:13, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.52G/9.94G [01:45<02:07, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.53G/9.94G [01:45<02:15, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.55G/9.94G [01:46<01:51, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.56G/9.94G [01:46<02:47, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.57G/9.94G [01:47<02:38, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.58G/9.94G [01:47<02:56, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.59G/9.94G [01:47<02:50, 31.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.60G/9.94G [01:47<02:18, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.61G/9.94G [01:48<02:10, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.62G/9.94G [01:48<02:21, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.65G/9.94G [01:48<02:12, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.66G/9.94G [01:49<01:58, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.67G/9.94G [01:49<02:03, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.68G/9.94G [01:49<02:19, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.70G/9.94G [01:50<01:56, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.71G/9.94G [01:50<02:11, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.73G/9.94G [01:50<01:51, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.74G/9.94G [01:51<02:13, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.76G/9.94G [01:51<01:54, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.77G/9.94G [01:51<02:01, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.79G/9.94G [01:52<01:53, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.80G/9.94G [01:52<02:02, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.82G/9.94G [01:52<01:43, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.83G/9.94G [01:53<01:55, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.84G/9.94G [01:53<01:40, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.85G/9.94G [01:53<01:51, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.87G/9.94G [01:53<01:56, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.89G/9.94G [01:54<02:03, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.90G/9.94G [01:55<02:41, 31.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.92G/9.94G [01:55<02:05, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.93G/9.94G [01:55<01:56, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.95G/9.94G [01:55<01:43, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.96G/9.94G [01:56<01:39, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.97G/9.94G [01:56<01:44, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 4.98G/9.94G [01:56<01:58, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 5.00G/9.94G [01:56<01:37, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 5.01G/9.94G [01:57<01:59, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.03G/9.94G [01:57<01:56, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.04G/9.94G [01:58<02:15, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.06G/9.94G [01:58<01:52, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.08G/9.94G [01:58<01:45, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.10G/9.94G [01:59<01:39, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.11G/9.94G [01:59<01:34, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.13G/9.94G [01:59<01:40, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.14G/9.94G [02:00<01:53, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.16G/9.94G [02:00<01:48, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.17G/9.94G [02:01<01:59, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.19G/9.94G [02:01<01:44, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.20G/9.94G [02:01<01:53, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.22G/9.94G [02:02<01:55, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.23G/9.94G [02:02<02:04, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.25G/9.94G [02:02<01:48, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.27G/9.94G [02:03<01:29, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.28G/9.94G [02:03<01:39, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.31G/9.94G [02:03<01:23, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.32G/9.94G [02:04<01:31, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.34G/9.94G [02:04<01:37, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.35G/9.94G [02:04<01:28, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.37G/9.94G [02:04<01:16, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.38G/9.94G [02:05<01:26, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.39G/9.94G [02:05<01:30, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.40G/9.94G [02:05<01:37, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.41G/9.94G [02:06<01:55, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.43G/9.94G [02:06<01:42, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.44G/9.94G [02:06<01:39, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.46G/9.94G [02:07<01:29, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.47G/9.94G [02:07<01:28, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.49G/9.94G [02:07<01:38, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.51G/9.94G [02:08<01:44, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.53G/9.94G [02:08<01:34, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.54G/9.94G [02:08<01:35, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.56G/9.94G [02:09<01:54, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.57G/9.94G [02:09<01:49, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.58G/9.94G [02:10<02:07, 34.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.59G/9.94G [02:10<02:01, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▎ | 5.61G/9.94G [02:10<01:43, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.62G/9.94G [02:10<01:37, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.63G/9.94G [02:11<01:36, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.64G/9.94G [02:11<01:28, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.65G/9.94G [02:11<01:28, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.66G/9.94G [02:11<01:24, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.67G/9.94G [02:11<01:21, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.68G/9.94G [02:12<01:35, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.70G/9.94G [02:12<01:34, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.71G/9.94G [02:12<01:38, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.74G/9.94G [02:13<01:33, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.75G/9.94G [02:13<01:33, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.77G/9.94G [02:13<01:19, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.78G/9.94G [02:14<01:26, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.80G/9.94G [02:14<01:16, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.81G/9.94G [02:14<01:32, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.83G/9.94G [02:15<01:30, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.84G/9.94G [02:15<01:36, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.85G/9.94G [02:15<01:22, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.86G/9.94G [02:16<01:26, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.87G/9.94G [02:16<01:44, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.89G/9.94G [02:16<01:41, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.90G/9.94G [02:17<01:31, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▍ | 5.91G/9.94G [02:17<01:32, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.92G/9.94G [02:17<01:40, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.95G/9.94G [02:18<01:30, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.96G/9.94G [02:18<01:28, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.98G/9.94G [02:18<01:28, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.99G/9.94G [02:18<01:29, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 6.01G/9.94G [02:19<01:17, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.02G/9.94G [02:19<01:34, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.04G/9.94G [02:20<01:20, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.05G/9.94G [02:20<01:27, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.06G/9.94G [02:20<01:25, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.07G/9.94G [02:20<01:35, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.08G/9.94G [02:21<01:59, 32.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.10G/9.94G [02:21<01:43, 37.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.11G/9.94G [02:22<01:53, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.13G/9.94G [02:22<01:43, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.14G/9.94G [02:23<01:42, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.17G/9.94G [02:23<01:27, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.18G/9.94G [02:23<01:40, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.20G/9.94G [02:24<01:33, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.22G/9.94G [02:24<01:23, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.23G/9.94G [02:25<01:43, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.25G/9.94G [02:25<01:24, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.26G/9.94G [02:25<01:27, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.27G/9.94G [02:25<01:23, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.28G/9.94G [02:26<01:23, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.29G/9.94G [02:26<01:39, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.31G/9.94G [02:27<01:35, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.32G/9.94G [02:27<01:42, 35.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.34G/9.94G [02:27<01:20, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.35G/9.94G [02:28<01:34, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.38G/9.94G [02:28<01:17, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.39G/9.94G [02:28<01:36, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.41G/9.94G [02:29<01:39, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.42G/9.94G [02:29<01:33, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.44G/9.94G [02:30<01:20, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.45G/9.94G [02:30<01:18, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.47G/9.94G [02:30<01:08, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.48G/9.94G [02:31<01:20, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.50G/9.94G [02:31<01:12, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.51G/9.94G [02:31<01:04, 53.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▌ | 6.52G/9.94G [02:31<01:04, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.53G/9.94G [02:32<01:07, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.55G/9.94G [02:32<01:06, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.56G/9.94G [02:32<01:18, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.59G/9.94G [02:33<01:20, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.60G/9.94G [02:33<01:26, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.62G/9.94G [02:34<01:33, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.63G/9.94G [02:34<01:29, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.64G/9.94G [02:34<01:21, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.65G/9.94G [02:34<01:15, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.66G/9.94G [02:35<01:26, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.68G/9.94G [02:35<01:15, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.69G/9.94G [02:35<01:17, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.71G/9.94G [02:36<01:15, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.72G/9.94G [02:36<01:15, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.74G/9.94G [02:36<00:57, 55.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.75G/9.94G [02:37<01:11, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.76G/9.94G [02:37<01:03, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.77G/9.94G [02:37<01:05, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.78G/9.94G [02:37<01:04, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.81G/9.94G [02:38<01:04, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▋ | 6.82G/9.94G [02:38<01:00, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▋ | 6.83G/9.94G [02:38<00:59, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.84G/9.94G [02:38<01:03, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.86G/9.94G [02:39<00:55, 55.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.87G/9.94G [02:39<01:03, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.88G/9.94G [02:39<01:03, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.89G/9.94G [02:40<01:04, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.90G/9.94G [02:40<01:15, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.92G/9.94G [02:40<01:05, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.93G/9.94G [02:41<01:12, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.95G/9.94G [02:41<01:00, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.96G/9.94G [02:41<01:03, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.98G/9.94G [02:42<01:01, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.99G/9.94G [02:42<01:06, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.01G/9.94G [02:43<01:25, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.03G/9.94G [02:43<01:14, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.05G/9.94G [02:43<01:10, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.06G/9.94G [02:44<01:07, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.08G/9.94G [02:44<00:57, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.09G/9.94G [02:44<01:02, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.10G/9.94G [02:44<00:57, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.11G/9.94G [02:45<01:06, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.12G/9.94G [02:45<00:58, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.13G/9.94G [02:45<01:11, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.14G/9.94G [02:45<01:15, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.16G/9.94G [02:46<01:05, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.17G/9.94G [02:46<01:09, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.19G/9.94G [02:47<00:58, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.20G/9.94G [02:47<01:10, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.21G/9.94G [02:47<01:10, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.22G/9.94G [02:47<01:03, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.24G/9.94G [02:48<01:16, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.26G/9.94G [02:48<01:00, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.27G/9.94G [02:48<00:59, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.28G/9.94G [02:49<00:59, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.29G/9.94G [02:49<01:03, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.30G/9.94G [02:49<00:58, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.32G/9.94G [02:50<01:02, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.33G/9.94G [02:50<01:05, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.35G/9.94G [02:50<01:05, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.36G/9.94G [02:51<01:06, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.38G/9.94G [02:51<01:03, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.39G/9.94G [02:52<01:08, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.41G/9.94G [02:52<01:00, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.42G/9.94G [02:52<00:54, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.43G/9.94G [02:52<00:50, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.44G/9.94G [02:53<00:52, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███ | 7.47G/9.94G [02:53<00:46, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███ | 7.48G/9.94G [02:53<00:49, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███ | 7.50G/9.94G [02:54<00:52, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.51G/9.94G [02:54<01:04, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.53G/9.94G [02:54<00:54, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.54G/9.94G [02:55<00:54, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.56G/9.94G [02:55<00:46, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.57G/9.94G [02:55<00:52, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.59G/9.94G [02:56<00:46, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.60G/9.94G [02:56<00:52, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.62G/9.94G [02:56<00:53, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.63G/9.94G [02:57<00:59, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.65G/9.94G [02:57<00:58, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.67G/9.94G [02:58<00:58, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.69G/9.94G [02:58<00:49, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.70G/9.94G [02:58<00:57, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.72G/9.94G [02:59<00:47, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.73G/9.94G [02:59<00:49, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.75G/9.94G [02:59<00:44, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.76G/9.94G [03:00<00:42, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.77G/9.94G [03:00<00:45, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.78G/9.94G [03:00<00:52, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.80G/9.94G [03:01<00:50, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.81G/9.94G [03:01<00:49, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.83G/9.94G [03:01<00:42, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.84G/9.94G [03:01<00:44, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.86G/9.94G [03:02<00:38, 54.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.87G/9.94G [03:02<00:46, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.90G/9.94G [03:02<00:39, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.91G/9.94G [03:03<00:46, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.93G/9.94G [03:03<00:37, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.94G/9.94G [03:03<00:45, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.96G/9.94G [03:04<00:38, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.97G/9.94G [03:04<00:45, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.99G/9.94G [03:05<00:47, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 8.00G/9.94G [03:05<00:50, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.01G/9.94G [03:05<00:51, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.02G/9.94G [03:06<00:51, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.03G/9.94G [03:06<01:01, 31.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.05G/9.94G [03:07<00:53, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.06G/9.94G [03:07<00:51, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.07G/9.94G [03:07<00:44, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▎| 8.08G/9.94G [03:07<00:47, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.11G/9.94G [03:08<00:40, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.12G/9.94G [03:08<00:49, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.14G/9.94G [03:09<00:50, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.15G/9.94G [03:09<00:51, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.17G/9.94G [03:09<00:43, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.18G/9.94G [03:10<00:46, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.20G/9.94G [03:10<00:36, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.21G/9.94G [03:10<00:41, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.23G/9.94G [03:11<00:35, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.24G/9.94G [03:11<00:40, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.26G/9.94G [03:11<00:34, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.27G/9.94G [03:12<00:38, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.29G/9.94G [03:12<00:35, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.30G/9.94G [03:12<00:38, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.33G/9.94G [03:13<00:34, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.34G/9.94G [03:13<00:36, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.35G/9.94G [03:13<00:33, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.36G/9.94G [03:14<00:34, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.37G/9.94G [03:14<00:33, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.38G/9.94G [03:14<00:32, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.39G/9.94G [03:14<00:37, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.41G/9.94G [03:15<00:31, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.42G/9.94G [03:15<00:38, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.44G/9.94G [03:15<00:30, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.45G/9.94G [03:16<00:31, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.47G/9.94G [03:16<00:26, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.48G/9.94G [03:16<00:34, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.50G/9.94G [03:17<00:27, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.51G/9.94G [03:17<00:31, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.54G/9.94G [03:17<00:26, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.55G/9.94G [03:17<00:27, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.57G/9.94G [03:18<00:22, 60.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.58G/9.94G [03:18<00:23, 58.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.60G/9.94G [03:18<00:21, 61.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.61G/9.94G [03:18<00:23, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.63G/9.94G [03:19<00:27, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.64G/9.94G [03:19<00:28, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.66G/9.94G [03:20<00:25, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.67G/9.94G [03:20<00:23, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.68G/9.94G [03:20<00:29, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.69G/9.94G [03:20<00:31, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.71G/9.94G [03:21<00:27, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.72G/9.94G [03:21<00:28, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.75G/9.94G [03:21<00:24, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.76G/9.94G [03:22<00:24, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.78G/9.94G [03:22<00:19, 58.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.79G/9.94G [03:22<00:21, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.81G/9.94G [03:22<00:18, 60.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.82G/9.94G [03:23<00:20, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.84G/9.94G [03:23<00:18, 59.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.85G/9.94G [03:23<00:21, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.87G/9.94G [03:24<00:17, 62.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.88G/9.94G [03:24<00:19, 53.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.90G/9.94G [03:24<00:18, 57.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.91G/9.94G [03:25<00:21, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.92G/9.94G [03:25<00:25, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.93G/9.94G [03:25<00:22, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.94G/9.94G [03:25<00:25, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.97G/9.94G [03:26<00:27, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.99G/9.94G [03:26<00:20, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 9.00G/9.94G [03:27<00:22, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.02G/9.94G [03:27<00:21, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.03G/9.94G [03:27<00:21, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.05G/9.94G [03:28<00:18, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.06G/9.94G [03:28<00:21, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.07G/9.94G [03:28<00:20, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.08G/9.94G [03:29<00:20, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.09G/9.94G [03:29<00:19, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.11G/9.94G [03:29<00:17, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.12G/9.94G [03:30<00:19, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.14G/9.94G [03:30<00:14, 55.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.15G/9.94G [03:30<00:18, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.18G/9.94G [03:31<00:15, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.19G/9.94G [03:31<00:17, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.21G/9.94G [03:31<00:14, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.22G/9.94G [03:32<00:16, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.24G/9.94G [03:32<00:13, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.25G/9.94G [03:32<00:15, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.27G/9.94G [03:32<00:13, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.28G/9.94G [03:33<00:13, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.29G/9.94G [03:33<00:12, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▋| 9.30G/9.94G [03:33<00:12, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.32G/9.94G [03:34<00:12, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.33G/9.94G [03:34<00:12, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.35G/9.94G [03:34<00:11, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.36G/9.94G [03:35<00:14, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.37G/9.94G [03:35<00:13, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.38G/9.94G [03:35<00:13, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.40G/9.94G [03:35<00:12, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.41G/9.94G [03:36<00:11, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.42G/9.94G [03:36<00:12, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.43G/9.94G [03:36<00:14, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.44G/9.94G [03:36<00:14, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.45G/9.94G [03:37<00:12, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.46G/9.94G [03:37<00:13, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.48G/9.94G [03:37<00:09, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.49G/9.94G [03:38<00:09, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.51G/9.94G [03:38<00:07, 59.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.52G/9.94G [03:38<00:09, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.54G/9.94G [03:39<00:08, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.55G/9.94G [03:39<00:11, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.57G/9.94G [03:40<00:10, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.58G/9.94G [03:40<00:10, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.59G/9.94G [03:40<00:09, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▊| 9.60G/9.94G [03:41<00:08, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▊| 9.63G/9.94G [03:41<00:08, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.64G/9.94G [03:41<00:07, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.65G/9.94G [03:41<00:06, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.66G/9.94G [03:42<00:06, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.67G/9.94G [03:42<00:06, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.69G/9.94G [03:42<00:05, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.70G/9.94G [03:43<00:05, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.72G/9.94G [03:43<00:04, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.73G/9.94G [03:43<00:05, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.75G/9.94G [03:44<00:04, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.76G/9.94G [03:44<00:04, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.78G/9.94G [03:44<00:03, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.79G/9.94G [03:45<00:03, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.81G/9.94G [03:45<00:02, 55.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.83G/9.94G [03:45<00:02, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.85G/9.94G [03:46<00:02, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.86G/9.94G [03:46<00:02, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.88G/9.94G [03:47<00:01, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.89G/9.94G [03:47<00:01, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.91G/9.94G [03:47<00:00, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.92G/9.94G [03:48<00:00, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.93G/9.94G [03:48<00:00, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|████| 9.94G/9.94G [03:48<00:00, 43.5MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████            | 1/2 [03:49<03:49, 229.04s/it]\n",
      "pytorch_model-00002-of-00002.bin:   0%|             | 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0%|    | 10.5M/4.54G [00:00<00:54, 83.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0%|    | 21.0M/4.54G [00:00<01:13, 61.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 31.5M/4.54G [00:00<01:22, 54.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 41.9M/4.54G [00:00<01:59, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 52.4M/4.54G [00:01<02:02, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|    | 62.9M/4.54G [00:01<01:46, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 73.4M/4.54G [00:01<01:38, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 83.9M/4.54G [00:02<02:24, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|    | 94.4M/4.54G [00:02<01:54, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|     | 105M/4.54G [00:02<01:48, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 115M/4.54G [00:02<01:54, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 136M/4.54G [00:03<01:39, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▏    | 147M/4.54G [00:03<02:03, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 168M/4.54G [00:03<01:33, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 178M/4.54G [00:04<01:37, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏    | 199M/4.54G [00:04<01:28, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 210M/4.54G [00:04<01:35, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 220M/4.54G [00:05<01:28, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 231M/4.54G [00:05<01:44, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▎    | 241M/4.54G [00:05<01:49, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 262M/4.54G [00:06<01:40, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 273M/4.54G [00:06<01:49, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 294M/4.54G [00:06<01:40, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 304M/4.54G [00:07<02:12, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 325M/4.54G [00:08<01:56, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 346M/4.54G [00:08<01:34, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 357M/4.54G [00:08<01:38, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍    | 377M/4.54G [00:08<01:26, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 388M/4.54G [00:09<01:23, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 409M/4.54G [00:09<01:15, 54.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 419M/4.54G [00:09<01:18, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 440M/4.54G [00:09<01:14, 55.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 451M/4.54G [00:10<01:27, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 461M/4.54G [00:10<01:36, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▌    | 472M/4.54G [00:10<01:39, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 482M/4.54G [00:11<01:29, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 493M/4.54G [00:11<01:21, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 503M/4.54G [00:11<01:27, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 514M/4.54G [00:11<01:36, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 535M/4.54G [00:12<01:21, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 545M/4.54G [00:12<01:25, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 566M/4.54G [00:12<01:07, 59.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 577M/4.54G [00:12<01:14, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 587M/4.54G [00:13<01:14, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 598M/4.54G [00:13<01:06, 59.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 608M/4.54G [00:13<01:28, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 629M/4.54G [00:13<01:11, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 640M/4.54G [00:14<01:12, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 650M/4.54G [00:14<01:19, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|▋    | 661M/4.54G [00:14<01:25, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|▊    | 682M/4.54G [00:15<01:19, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|▊    | 692M/4.54G [00:15<01:20, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 713M/4.54G [00:15<01:07, 57.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 724M/4.54G [00:15<01:15, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 744M/4.54G [00:16<01:14, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 755M/4.54G [00:16<01:14, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 776M/4.54G [00:16<01:15, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 786M/4.54G [00:17<01:22, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 807M/4.54G [00:17<01:12, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 818M/4.54G [00:17<01:23, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 839M/4.54G [00:18<01:11, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 849M/4.54G [00:18<01:20, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 870M/4.54G [00:18<01:11, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 881M/4.54G [00:19<01:22, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|▉    | 902M/4.54G [00:19<01:05, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|█    | 912M/4.54G [00:19<01:14, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█    | 933M/4.54G [00:20<01:15, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█    | 944M/4.54G [00:20<01:06, 53.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█    | 954M/4.54G [00:20<01:09, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█    | 965M/4.54G [00:20<01:06, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█    | 975M/4.54G [00:20<01:00, 58.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|█    | 986M/4.54G [00:20<01:01, 57.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|█    | 996M/4.54G [00:21<01:13, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|▉   | 1.02G/4.54G [00:21<01:06, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.03G/4.54G [00:21<01:06, 52.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.05G/4.54G [00:22<01:02, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|▉   | 1.06G/4.54G [00:22<01:11, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.08G/4.54G [00:23<01:20, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.09G/4.54G [00:23<01:53, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.10G/4.54G [00:23<01:41, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|▉   | 1.11G/4.54G [00:24<01:37, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|▉   | 1.12G/4.54G [00:24<01:52, 30.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|▉   | 1.13G/4.54G [00:24<01:43, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|█   | 1.14G/4.54G [00:25<01:36, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|█   | 1.15G/4.54G [00:25<01:42, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.17G/4.54G [00:25<01:18, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|█   | 1.18G/4.54G [00:26<01:32, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.21G/4.54G [00:26<01:17, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.22G/4.54G [00:26<01:17, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.24G/4.54G [00:27<01:09, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|█   | 1.25G/4.54G [00:27<01:08, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|█   | 1.26G/4.54G [00:27<01:03, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|█   | 1.27G/4.54G [00:27<01:10, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|█▏  | 1.29G/4.54G [00:28<01:07, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.30G/4.54G [00:28<01:10, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.31G/4.54G [00:28<01:03, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.32G/4.54G [00:28<01:04, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▏  | 1.33G/4.54G [00:29<01:08, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.35G/4.54G [00:29<01:00, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.36G/4.54G [00:29<01:10, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▏  | 1.38G/4.54G [00:30<01:20, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▏  | 1.39G/4.54G [00:30<01:27, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▏  | 1.42G/4.54G [00:31<01:15, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▎  | 1.43G/4.54G [00:31<01:24, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.45G/4.54G [00:32<01:09, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▎  | 1.46G/4.54G [00:32<01:06, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.48G/4.54G [00:32<01:01, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.49G/4.54G [00:32<01:10, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.51G/4.54G [00:33<00:58, 51.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▎  | 1.52G/4.54G [00:33<01:06, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.53G/4.54G [00:33<01:00, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.54G/4.54G [00:33<01:02, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▎  | 1.55G/4.54G [00:34<01:01, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▍  | 1.56G/4.54G [00:34<00:56, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.57G/4.54G [00:34<01:03, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.59G/4.54G [00:34<00:55, 53.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|█▍  | 1.60G/4.54G [00:35<01:02, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.63G/4.54G [00:35<00:58, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.64G/4.54G [00:35<01:05, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.65G/4.54G [00:36<00:57, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▍  | 1.66G/4.54G [00:36<00:55, 51.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.67G/4.54G [00:36<00:55, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.69G/4.54G [00:36<00:47, 60.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|█▍  | 1.70G/4.54G [00:37<00:58, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.72G/4.54G [00:37<00:46, 60.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▌  | 1.73G/4.54G [00:37<00:57, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.75G/4.54G [00:37<00:47, 58.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.76G/4.54G [00:38<00:55, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.77G/4.54G [00:38<00:49, 56.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.78G/4.54G [00:38<01:02, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▌  | 1.79G/4.54G [00:39<01:09, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 1.81G/4.54G [00:39<00:56, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|█▌  | 1.82G/4.54G [00:39<00:59, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 1.85G/4.54G [00:40<01:04, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 1.86G/4.54G [00:40<01:04, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 1.87G/4.54G [00:40<01:04, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|█▋  | 1.88G/4.54G [00:41<01:16, 34.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 1.89G/4.54G [00:41<01:04, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 1.90G/4.54G [00:41<01:01, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 1.91G/4.54G [00:41<01:11, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 1.92G/4.54G [00:41<00:59, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|█▋  | 1.93G/4.54G [00:42<00:54, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 1.94G/4.54G [00:42<00:54, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 1.95G/4.54G [00:42<00:46, 56.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 1.96G/4.54G [00:42<01:01, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|█▋  | 1.97G/4.54G [00:43<01:03, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▊  | 1.99G/4.54G [00:43<00:52, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|█▊  | 2.00G/4.54G [00:43<01:04, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.02G/4.54G [00:44<00:51, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.03G/4.54G [00:44<00:59, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.06G/4.54G [00:44<00:47, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|█▊  | 2.07G/4.54G [00:45<00:51, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.09G/4.54G [00:45<00:50, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|█▊  | 2.10G/4.54G [00:45<00:59, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▊  | 2.12G/4.54G [00:46<00:51, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 2.13G/4.54G [00:46<00:54, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 2.15G/4.54G [00:46<00:47, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.16G/4.54G [00:47<00:55, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.17G/4.54G [00:47<00:50, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.18G/4.54G [00:47<00:56, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.19G/4.54G [00:47<00:47, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 2.20G/4.54G [00:47<00:42, 55.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.21G/4.54G [00:48<00:54, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.23G/4.54G [00:48<00:54, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 2.24G/4.54G [00:49<00:59, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|█▉  | 2.26G/4.54G [00:49<00:49, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|██  | 2.28G/4.54G [00:49<00:52, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.30G/4.54G [00:50<00:48, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.31G/4.54G [00:50<00:50, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.33G/4.54G [00:50<00:49, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 2.34G/4.54G [00:51<00:58, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.36G/4.54G [00:51<00:57, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 2.37G/4.54G [00:52<01:00, 35.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 2.39G/4.54G [00:52<00:58, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 2.40G/4.54G [00:53<00:58, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|██▏ | 2.42G/4.54G [00:53<00:54, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.43G/4.54G [00:54<00:58, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.45G/4.54G [00:54<00:45, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 2.46G/4.54G [00:54<00:47, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.49G/4.54G [00:55<00:45, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.50G/4.54G [00:55<00:48, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.51G/4.54G [00:55<00:45, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 2.52G/4.54G [00:55<00:43, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▏ | 2.53G/4.54G [00:55<00:40, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▏ | 2.54G/4.54G [00:56<00:36, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▏ | 2.55G/4.54G [00:56<00:37, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|██▎ | 2.57G/4.54G [00:56<00:38, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|██▎ | 2.58G/4.54G [00:56<00:36, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|██▎ | 2.60G/4.54G [00:57<00:37, 52.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|██▎ | 2.61G/4.54G [00:57<00:39, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|██▎ | 2.63G/4.54G [00:57<00:38, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|██▎ | 2.64G/4.54G [00:58<00:43, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|██▎ | 2.66G/4.54G [00:58<00:34, 53.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|██▎ | 2.67G/4.54G [00:58<00:43, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|██▎ | 2.69G/4.54G [00:59<00:41, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██▍ | 2.71G/4.54G [00:59<00:43, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██▍ | 2.73G/4.54G [00:59<00:35, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██▍ | 2.74G/4.54G [01:00<00:37, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██▍ | 2.75G/4.54G [01:00<00:33, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██▍ | 2.76G/4.54G [01:00<00:39, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██▍ | 2.77G/4.54G [01:00<00:39, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██▍ | 2.79G/4.54G [01:01<00:37, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██▍ | 2.80G/4.54G [01:01<00:45, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██▍ | 2.81G/4.54G [01:01<00:38, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██▍ | 2.82G/4.54G [01:02<00:45, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██▌ | 2.84G/4.54G [01:02<00:34, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██▌ | 2.85G/4.54G [01:02<00:33, 49.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██▌ | 2.87G/4.54G [01:03<00:31, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██▌ | 2.88G/4.54G [01:03<00:35, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██▌ | 2.90G/4.54G [01:03<00:30, 53.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██▌ | 2.92G/4.54G [01:04<00:40, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██▌ | 2.94G/4.54G [01:04<00:34, 45.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██▌ | 2.95G/4.54G [01:04<00:36, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██▌ | 2.97G/4.54G [01:05<00:29, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██▌ | 2.98G/4.54G [01:05<00:35, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██▋ | 3.00G/4.54G [01:05<00:36, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██▋ | 3.01G/4.54G [01:06<00:34, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██▋ | 3.03G/4.54G [01:06<00:30, 49.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██▋ | 3.04G/4.54G [01:06<00:33, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██▋ | 3.05G/4.54G [01:06<00:30, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██▋ | 3.06G/4.54G [01:07<00:33, 43.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██▋ | 3.07G/4.54G [01:07<00:37, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██▋ | 3.09G/4.54G [01:08<00:33, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██▋ | 3.11G/4.54G [01:08<00:27, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██▊ | 3.12G/4.54G [01:08<00:34, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██▊ | 3.15G/4.54G [01:09<00:29, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|██▊ | 3.16G/4.54G [01:09<00:30, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|██▊ | 3.18G/4.54G [01:09<00:31, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|██▊ | 3.19G/4.54G [01:10<00:41, 32.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|██▊ | 3.21G/4.54G [01:10<00:34, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|██▊ | 3.22G/4.54G [01:11<00:35, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|██▊ | 3.24G/4.54G [01:11<00:32, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|██▊ | 3.25G/4.54G [01:11<00:30, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|██▉ | 3.27G/4.54G [01:12<00:31, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|██▉ | 3.28G/4.54G [01:12<00:30, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|██▉ | 3.30G/4.54G [01:13<00:28, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|██▉ | 3.31G/4.54G [01:13<00:29, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|██▉ | 3.32G/4.54G [01:13<00:26, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|██▉ | 3.33G/4.54G [01:13<00:30, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|██▉ | 3.36G/4.54G [01:14<00:21, 56.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|██▉ | 3.37G/4.54G [01:14<00:24, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|██▉ | 3.38G/4.54G [01:14<00:26, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|██▉ | 3.40G/4.54G [01:15<00:22, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|███ | 3.42G/4.54G [01:15<00:18, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███ | 3.43G/4.54G [01:15<00:20, 53.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███ | 3.45G/4.54G [01:15<00:20, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███ | 3.46G/4.54G [01:16<00:22, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███ | 3.47G/4.54G [01:16<00:20, 51.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███ | 3.48G/4.54G [01:16<00:27, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███ | 3.49G/4.54G [01:17<00:27, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███ | 3.51G/4.54G [01:17<00:26, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███ | 3.52G/4.54G [01:18<00:29, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███ | 3.53G/4.54G [01:18<00:24, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███ | 3.54G/4.54G [01:18<00:27, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███▏| 3.55G/4.54G [01:18<00:25, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███▏| 3.57G/4.54G [01:19<00:23, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███▏| 3.58G/4.54G [01:19<00:22, 42.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███▏| 3.59G/4.54G [01:19<00:23, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███▏| 3.61G/4.54G [01:19<00:16, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███▏| 3.62G/4.54G [01:20<00:31, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███▏| 3.64G/4.54G [01:21<00:28, 31.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███▏| 3.65G/4.54G [01:21<00:28, 31.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|███▏| 3.66G/4.54G [01:21<00:23, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|███▏| 3.67G/4.54G [01:21<00:24, 36.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|███▏| 3.68G/4.54G [01:22<00:23, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 3.70G/4.54G [01:22<00:22, 36.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 3.71G/4.54G [01:22<00:19, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 3.72G/4.54G [01:23<00:19, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 3.73G/4.54G [01:23<00:21, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 3.74G/4.54G [01:23<00:20, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|███▎| 3.75G/4.54G [01:24<00:21, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|███▎| 3.76G/4.54G [01:24<00:22, 34.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|███▎| 3.79G/4.54G [01:24<00:19, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|███▎| 3.80G/4.54G [01:25<00:18, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|███▎| 3.81G/4.54G [01:25<00:18, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|███▎| 3.82G/4.54G [01:25<00:19, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|███▎| 3.83G/4.54G [01:26<00:19, 36.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 3.84G/4.54G [01:26<00:17, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 3.85G/4.54G [01:26<00:15, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 3.86G/4.54G [01:26<00:16, 40.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 3.87G/4.54G [01:26<00:14, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 3.88G/4.54G [01:27<00:13, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|███▍| 3.89G/4.54G [01:27<00:16, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|███▍| 3.90G/4.54G [01:27<00:13, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|███▍| 3.91G/4.54G [01:28<00:17, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|███▍| 3.92G/4.54G [01:28<00:13, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|███▍| 3.94G/4.54G [01:28<00:12, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|███▍| 3.95G/4.54G [01:28<00:14, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 3.97G/4.54G [01:29<00:11, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 3.98G/4.54G [01:29<00:15, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 4.00G/4.54G [01:29<00:13, 39.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 4.01G/4.54G [01:30<00:12, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 4.02G/4.54G [01:30<00:12, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|███▌| 4.03G/4.54G [01:30<00:10, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|███▌| 4.04G/4.54G [01:30<00:10, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|███▌| 4.05G/4.54G [01:30<00:09, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|███▌| 4.06G/4.54G [01:31<00:10, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|███▌| 4.07G/4.54G [01:31<00:11, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|███▌| 4.08G/4.54G [01:31<00:09, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|███▌| 4.09G/4.54G [01:31<00:09, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|███▌| 4.10G/4.54G [01:32<00:13, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|███▌| 4.11G/4.54G [01:32<00:11, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|███▋| 4.12G/4.54G [01:33<00:14, 28.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|███▋| 4.13G/4.54G [01:33<00:11, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|███▋| 4.15G/4.54G [01:33<00:07, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|███▋| 4.16G/4.54G [01:33<00:08, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|███▋| 4.18G/4.54G [01:34<00:06, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|███▋| 4.19G/4.54G [01:34<00:06, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|███▋| 4.20G/4.54G [01:34<00:06, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|███▋| 4.22G/4.54G [01:35<00:09, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|███▋| 4.23G/4.54G [01:35<00:07, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▋| 4.25G/4.54G [01:35<00:05, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▊| 4.26G/4.54G [01:35<00:06, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▊| 4.28G/4.54G [01:36<00:06, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▊| 4.29G/4.54G [01:36<00:05, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|███▊| 4.31G/4.54G [01:37<00:05, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|███▊| 4.32G/4.54G [01:37<00:05, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|███▊| 4.34G/4.54G [01:37<00:03, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|███▊| 4.35G/4.54G [01:37<00:04, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|███▊| 4.36G/4.54G [01:38<00:04, 42.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|███▊| 4.37G/4.54G [01:38<00:04, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|███▊| 4.39G/4.54G [01:38<00:02, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|███▉| 4.40G/4.54G [01:39<00:03, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|███▉| 4.42G/4.54G [01:39<00:02, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|███▉| 4.44G/4.54G [01:39<00:02, 49.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|███▉| 4.46G/4.54G [01:40<00:01, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|███▉| 4.47G/4.54G [01:40<00:01, 45.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|███▉| 4.49G/4.54G [01:40<00:01, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|███▉| 4.50G/4.54G [01:41<00:00, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|███▉| 4.52G/4.54G [01:41<00:00, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|███▉| 4.53G/4.54G [01:41<00:00, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|████| 4.54G/4.54G [01:41<00:00, 44.5MB/s]\u001b[A\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [05:31<00:00, 165.73s/it]\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:44<00:00, 22.09s/it]\n",
      "generation_config.json: 100%|███████████████████| 116/116 [00:00<00:00, 631kB/s]\n",
      "  0%|                                                    | 0/80 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▌                                           | 1/80 [00:37<49:54, 37.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|█                                           | 2/80 [01:16<50:04, 38.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|█▋                                          | 3/80 [01:54<48:48, 38.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|██▏                                         | 4/80 [02:31<47:51, 37.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|██▊                                         | 5/80 [03:09<47:16, 37.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|███▎                                        | 6/80 [03:48<47:09, 38.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|███▊                                        | 7/80 [04:08<39:22, 32.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|████▍                                       | 8/80 [04:46<41:00, 34.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|████▉                                       | 9/80 [05:26<42:16, 35.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█████▍                                     | 10/80 [05:54<39:05, 33.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█████▉                                     | 11/80 [06:32<39:58, 34.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|██████▍                                    | 12/80 [07:10<40:41, 35.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|██████▉                                    | 13/80 [07:49<40:58, 36.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|███████▌                                   | 14/80 [08:16<37:21, 33.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|████████                                   | 15/80 [08:56<38:31, 35.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|████████▌                                  | 16/80 [09:34<38:49, 36.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|█████████▏                                 | 17/80 [09:54<33:08, 31.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|█████████▋                                 | 18/80 [10:33<34:49, 33.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██████████▏                                | 19/80 [11:02<32:57, 32.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██████████▊                                | 20/80 [11:41<34:23, 34.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|███████████▎                               | 21/80 [12:02<29:39, 30.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|███████████▊                               | 22/80 [12:30<28:35, 29.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|████████████▎                              | 23/80 [13:07<30:18, 31.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|████████████▉                              | 24/80 [13:39<29:37, 31.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|█████████████▍                             | 25/80 [14:17<30:52, 33.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|█████████████▉                             | 26/80 [14:56<31:50, 35.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|██████████████▌                            | 27/80 [15:35<32:02, 36.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███████████████                            | 28/80 [16:12<31:46, 36.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███████████████▌                           | 29/80 [16:50<31:34, 37.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|████████████████▏                          | 30/80 [17:28<31:02, 37.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|████████████████▋                          | 31/80 [17:49<26:32, 32.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|█████████████████▏                         | 32/80 [18:27<27:18, 34.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|█████████████████▋                         | 33/80 [19:07<28:01, 35.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|██████████████████▎                        | 34/80 [19:46<28:10, 36.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|██████████████████▊                        | 35/80 [20:24<27:47, 37.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|███████████████████▎                       | 36/80 [21:03<27:36, 37.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|███████████████████▉                       | 37/80 [21:40<26:56, 37.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████████████████████▍                      | 38/80 [22:19<26:37, 38.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████████████████████▉                      | 39/80 [22:58<26:13, 38.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████████████████████▌                     | 40/80 [23:36<25:22, 38.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|██████████████████████                     | 41/80 [24:14<24:52, 38.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|██████████████████████▌                    | 42/80 [24:53<24:14, 38.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|███████████████████████                    | 43/80 [25:31<23:30, 38.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|███████████████████████▋                   | 44/80 [25:58<20:59, 34.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|████████████████████████▏                  | 45/80 [26:37<20:59, 35.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|████████████████████████▋                  | 46/80 [27:14<20:41, 36.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████████████████████████▎                 | 47/80 [27:52<20:14, 36.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████████████████████████▊                 | 48/80 [28:07<16:12, 30.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████████████████████████▎                | 49/80 [28:46<17:00, 32.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████████████████████████▉                | 50/80 [29:25<17:23, 34.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|███████████████████████████▍               | 51/80 [30:04<17:23, 35.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|███████████████████████████▉               | 52/80 [30:43<17:10, 36.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|████████████████████████████▍              | 53/80 [31:22<16:51, 37.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|█████████████████████████████              | 54/80 [31:59<16:16, 37.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|█████████████████████████████▌             | 55/80 [32:22<13:44, 32.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████████████████████████████             | 56/80 [32:59<13:44, 34.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|██████████████████████████████▋            | 57/80 [33:21<11:41, 30.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████████████████████████████▏           | 58/80 [33:59<12:01, 32.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████████████████████████████▋           | 59/80 [34:37<12:04, 34.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|████████████████████████████████▎          | 60/80 [35:15<11:50, 35.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|████████████████████████████████▊          | 61/80 [35:54<11:32, 36.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|█████████████████████████████████▎         | 62/80 [36:34<11:13, 37.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|█████████████████████████████████▊         | 63/80 [37:12<10:42, 37.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|██████████████████████████████████▍        | 64/80 [37:51<10:11, 38.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|██████████████████████████████████▉        | 65/80 [38:21<08:52, 35.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|███████████████████████████████████▍       | 66/80 [39:00<08:31, 36.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████████████████████████████████       | 67/80 [39:38<08:01, 37.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████████████████████████████████▌      | 68/80 [40:16<07:27, 37.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|█████████████████████████████████████      | 69/80 [40:53<06:51, 37.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|█████████████████████████████████████▋     | 70/80 [41:31<06:14, 37.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|██████████████████████████████████████▏    | 71/80 [41:59<05:12, 34.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|██████████████████████████████████████▋    | 72/80 [42:37<04:45, 35.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|███████████████████████████████████████▏   | 73/80 [43:14<04:13, 36.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|███████████████████████████████████████▊   | 74/80 [43:53<03:40, 36.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|████████████████████████████████████████▎  | 75/80 [44:31<03:05, 37.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|████████████████████████████████████████▊  | 76/80 [45:09<02:29, 37.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████████████████████████████████████▍ | 77/80 [45:29<01:36, 32.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████████████████████████████████████▉ | 78/80 [46:07<01:08, 34.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|██████████████████████████████████████████▍| 79/80 [46:47<00:35, 35.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|███████████████████████████████████████████| 80/80 [47:24<00:00, 35.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# make sure that is the correct path\n",
    "model_path=\"cognitivecomputations/dolphin-2.1-mistral-7b\"\n",
    "# model id will be used to load our conversation template https://github.com/lm-sys/FastChat/blob/1db84d0906196673db361eac50d5aa65180a0ffe/fastchat/model/model_adapter.py#L1579\n",
    "model_id=\"mistral-dolphin-sft\"\n",
    "\n",
    "# generate model answer\n",
    "!python gen_model_answer.py --model-id {model_id} --model-path {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74102679-0b9a-424d-a90c-b43fb4aad8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output to data/mt_bench/model_answer/mistral-dolphin-dpo.jsonl\n",
      "tokenizer_config.json: 100%|███████████████| 1.70k/1.70k [00:00<00:00, 7.03MB/s]\n",
      "tokenizer.model: 100%|████████████████████████| 493k/493k [00:00<00:00, 117MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 20.0MB/s]\n",
      "added_tokens.json: 100%|██████████████████████| 51.0/51.0 [00:00<00:00, 244kB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 445/445 [00:00<00:00, 2.15MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "adapter_config.json: 100%|█████████████████████| 696/696 [00:00<00:00, 2.80MB/s]\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:50<00:00, 25.11s/it]\n",
      "adapter_model.safetensors: 100%|█████████████| 336M/336M [00:13<00:00, 24.4MB/s]\n",
      "  0%|                                                    | 0/80 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▌                                         | 1/80 [00:57<1:15:40, 57.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|█                                         | 2/80 [01:56<1:15:33, 58.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|█▌                                        | 3/80 [02:53<1:14:18, 57.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|██                                        | 4/80 [03:52<1:13:38, 58.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|██▋                                       | 5/80 [04:49<1:12:29, 57.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|███▏                                      | 6/80 [05:47<1:11:31, 57.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|███▋                                      | 7/80 [06:45<1:10:27, 57.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|████▏                                     | 8/80 [07:43<1:09:36, 58.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|████▋                                     | 9/80 [08:41<1:08:28, 57.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█████▏                                   | 10/80 [09:39<1:07:39, 58.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█████▋                                   | 11/80 [10:37<1:06:44, 58.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|██████▏                                  | 12/80 [11:35<1:05:49, 58.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|██████▋                                  | 13/80 [12:34<1:05:00, 58.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|███████▏                                 | 14/80 [13:33<1:04:08, 58.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|███████▋                                 | 15/80 [14:30<1:02:52, 58.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|████████▏                                | 16/80 [15:29<1:02:08, 58.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|████████▋                                | 17/80 [16:26<1:00:59, 58.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|█████████▏                               | 18/80 [17:25<1:00:04, 58.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██████████▏                                | 19/80 [18:22<59:00, 58.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██████████▊                                | 20/80 [19:21<58:08, 58.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|███████████▎                               | 21/80 [20:18<56:56, 57.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|███████████▊                               | 22/80 [21:15<55:47, 57.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|████████████▎                              | 23/80 [22:14<54:55, 57.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|████████████▉                              | 24/80 [23:12<54:06, 57.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|█████████████▍                             | 25/80 [24:10<53:13, 58.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|█████████████▉                             | 26/80 [25:08<52:13, 58.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|██████████████▌                            | 27/80 [26:07<51:23, 58.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███████████████                            | 28/80 [27:04<50:12, 57.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███████████████▌                           | 29/80 [28:01<49:06, 57.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|████████████████▏                          | 30/80 [28:59<48:08, 57.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|████████████████▋                          | 31/80 [29:57<47:16, 57.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|█████████████████▏                         | 32/80 [30:56<46:24, 58.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|█████████████████▋                         | 33/80 [31:54<45:32, 58.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|██████████████████▎                        | 34/80 [32:52<44:34, 58.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|██████████████████▊                        | 35/80 [33:50<43:25, 57.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|███████████████████▎                       | 36/80 [34:48<42:30, 57.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|███████████████████▉                       | 37/80 [35:46<41:34, 58.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████████████████████▍                      | 38/80 [36:43<40:27, 57.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████████████████████▉                      | 39/80 [37:40<39:20, 57.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████████████████████▌                     | 40/80 [38:37<38:20, 57.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|██████████████████████                     | 41/80 [39:36<37:30, 57.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|██████████████████████▌                    | 42/80 [40:33<36:30, 57.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|███████████████████████                    | 43/80 [41:32<35:42, 57.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Change this to where you saved the model during training, remember our current directory is FastChat/\n",
    "model_path=\"DrishtiSharma/doplhin-mistral-dpo-ultrafeedback-binarized-preferences-sigmoid\"\n",
    "\n",
    "# model id will be used to load our conversation template https://github.com/lm-sys/FastChat/blob/1db84d0906196673db361eac50d5aa65180a0ffe/fastchat/model/model_adapter.py#L1579\n",
    "model_id=\"mistral-dolphin-dpo\"\n",
    "\n",
    "# generate model answer\n",
    "!python gen_model_answer.py --model-id {model_id} --model-path {model_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "574d12c0-864f-4f0c-8f3f-a922d3cd67d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats:\n",
      "{\n",
      "    \"bench_name\": \"mt_bench\",\n",
      "    \"mode\": \"pairwise-all\",\n",
      "    \"judge\": \"gpt-4-1106-preview\",\n",
      "    \"baseline\": null,\n",
      "    \"model_list\": [\n",
      "        \"mistral-dolphin-dpo\",\n",
      "        \"mistral-dolphin-sft\"\n",
      "    ],\n",
      "    \"total_num_questions\": 80,\n",
      "    \"total_num_matches\": 160,\n",
      "    \"output_path\": \"data/mt_bench/model_judgment/gpt-4-1106-preview_pair.jsonl\"\n",
      "}\n",
      "Evaluating the following models.\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]question: 81, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  1%|▎                                          | 1/160 [00:22<59:42, 22.53s/it]question: 82, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  1%|▌                                          | 2/160 [00:44<57:52, 21.98s/it]question: 83, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  2%|▊                                          | 3/160 [00:57<47:28, 18.14s/it]question: 84, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  2%|█                                          | 4/160 [00:59<30:15, 11.64s/it]question: 85, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  3%|█▎                                         | 5/160 [01:01<21:30,  8.32s/it]question: 86, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  4%|█▌                                         | 6/160 [01:14<25:05,  9.78s/it]question: 87, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  4%|█▉                                         | 7/160 [01:42<40:04, 15.72s/it]question: 88, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: error, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  5%|██▏                                        | 8/160 [02:05<45:58, 18.15s/it]question: 89, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  6%|██▍                                        | 9/160 [02:09<33:59, 13.51s/it]question: 90, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  6%|██▋                                       | 10/160 [02:20<32:12, 12.88s/it]question: 91, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  7%|██▉                                       | 11/160 [02:42<38:43, 15.60s/it]question: 92, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  8%|███▏                                      | 12/160 [03:22<57:09, 23.17s/it]question: 93, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  8%|███▍                                      | 13/160 [03:34<48:15, 19.69s/it]question: 94, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  9%|███▋                                      | 14/160 [03:51<46:06, 18.95s/it]question: 95, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      "  9%|███▊                                    | 15/160 [04:49<1:13:46, 30.53s/it]question: 96, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 10%|████                                    | 16/160 [05:23<1:15:53, 31.62s/it]question: 97, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 11%|████▎                                   | 17/160 [05:42<1:06:44, 28.01s/it]question: 98, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 11%|████▌                                   | 18/160 [06:05<1:02:26, 26.39s/it]question: 99, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 12%|████▉                                     | 19/160 [06:19<53:20, 22.70s/it]question: 100, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 12%|█████▎                                    | 20/160 [06:21<38:11, 16.37s/it]question: 131, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 13%|█████▌                                    | 21/160 [06:37<37:53, 16.36s/it]question: 132, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 14%|█████▊                                    | 22/160 [06:47<33:09, 14.42s/it]question: 133, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 14%|██████                                    | 23/160 [06:49<24:12, 10.60s/it]question: 134, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 15%|██████▎                                   | 24/160 [07:06<28:29, 12.57s/it]question: 135, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 16%|██████▌                                   | 25/160 [07:08<21:07,  9.39s/it]question: 136, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 16%|██████▊                                   | 26/160 [07:35<32:54, 14.74s/it]question: 137, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 17%|███████                                   | 27/160 [07:47<31:12, 14.08s/it]question: 138, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 18%|███████▎                                  | 28/160 [08:21<43:44, 19.89s/it]question: 139, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 18%|███████▌                                  | 29/160 [08:40<43:14, 19.81s/it]question: 140, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 19%|███████▉                                  | 30/160 [09:03<44:59, 20.76s/it]question: 141, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 19%|████████▏                                 | 31/160 [09:05<32:28, 15.11s/it]question: 142, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 20%|████████▍                                 | 32/160 [09:34<41:03, 19.25s/it]question: 143, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 21%|████████▋                                 | 33/160 [10:17<55:46, 26.35s/it]question: 144, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 21%|████████▉                                 | 34/160 [10:25<43:32, 20.73s/it]question: 145, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 22%|████████▊                               | 35/160 [11:21<1:05:34, 31.47s/it]question: 146, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 22%|█████████▍                                | 36/160 [11:24<47:04, 22.78s/it]question: 147, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 23%|█████████▋                                | 37/160 [11:51<49:23, 24.09s/it]question: 148, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 24%|█████████▉                                | 38/160 [12:23<53:35, 26.36s/it]question: 149, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 24%|██████████▏                               | 39/160 [12:56<57:24, 28.47s/it]question: 150, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 25%|██████████▌                               | 40/160 [12:59<41:24, 20.70s/it]question: 151, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 26%|██████████▊                               | 41/160 [13:23<43:03, 21.71s/it]question: 152, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 26%|███████████                               | 42/160 [13:32<35:35, 18.10s/it]question: 153, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 27%|███████████▎                              | 43/160 [14:09<45:50, 23.51s/it]question: 154, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 28%|███████████▌                              | 44/160 [14:54<58:16, 30.15s/it]question: 155, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 28%|███████████▊                              | 45/160 [15:10<49:31, 25.84s/it]question: 156, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 29%|████████████                              | 46/160 [15:33<47:33, 25.03s/it]question: 157, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 29%|████████████▎                             | 47/160 [16:04<50:34, 26.86s/it]question: 158, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 30%|████████████▌                             | 48/160 [16:16<41:47, 22.39s/it]question: 159, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 31%|████████████▊                             | 49/160 [17:06<56:37, 30.61s/it]question: 160, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2')\n",
      " 31%|█████████████▏                            | 50/160 [17:25<49:35, 27.05s/it]question: 101, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 32%|█████████████▍                            | 51/160 [18:04<55:58, 30.81s/it]question: 102, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 32%|█████████████▋                            | 52/160 [18:31<53:21, 29.64s/it]question: 103, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 33%|█████████████▉                            | 53/160 [18:57<50:48, 28.49s/it]question: 104, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 34%|██████████████▏                           | 54/160 [19:30<52:29, 29.71s/it]question: 105, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 34%|██████████████▍                           | 55/160 [19:57<50:47, 29.02s/it]question: 106, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 35%|██████████████▋                           | 56/160 [20:31<52:46, 30.44s/it]question: 107, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 36%|██████████████▉                           | 57/160 [20:55<49:08, 28.63s/it]question: 108, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 36%|███████████████▏                          | 58/160 [21:19<46:04, 27.11s/it]question: 109, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 37%|███████████████▍                          | 59/160 [21:53<49:16, 29.27s/it]question: 110, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 38%|███████████████▊                          | 60/160 [22:14<44:46, 26.86s/it]question: 111, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 38%|████████████████                          | 61/160 [22:39<43:22, 26.29s/it]question: 112, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 39%|████████████████▎                         | 62/160 [23:09<44:51, 27.46s/it]question: 113, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 39%|████████████████▌                         | 63/160 [23:56<53:51, 33.32s/it]question: 114, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 40%|████████████████▊                         | 64/160 [24:29<52:45, 32.98s/it]question: 115, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 41%|█████████████████                         | 65/160 [25:13<57:44, 36.47s/it]question: 116, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 41%|█████████████████▎                        | 66/160 [25:47<55:59, 35.74s/it]question: 117, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 42%|█████████████████▌                        | 67/160 [26:23<55:37, 35.89s/it]question: 118, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 42%|█████████████████▊                        | 68/160 [26:48<49:48, 32.48s/it]question: 119, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 43%|██████████████████                        | 69/160 [27:07<43:12, 28.49s/it]question: 120, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 44%|██████████████████▍                       | 70/160 [27:47<47:39, 31.77s/it]question: 121, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 44%|██████████████████▋                       | 71/160 [28:16<46:17, 31.21s/it]question: 122, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 45%|██████████████████▉                       | 72/160 [28:51<47:03, 32.09s/it]question: 123, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 46%|███████████████████▏                      | 73/160 [29:29<49:12, 33.93s/it]question: 124, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 46%|███████████████████▍                      | 74/160 [30:18<54:58, 38.36s/it]question: 125, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 47%|███████████████████▋                      | 75/160 [30:39<47:01, 33.19s/it]question: 126, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 48%|███████████████████▉                      | 76/160 [31:16<48:08, 34.39s/it]question: 127, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 48%|████████████████████▏                     | 77/160 [31:39<42:52, 31.00s/it]question: 128, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 49%|████████████████████▍                     | 78/160 [32:10<42:30, 31.10s/it]question: 129, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 49%|████████████████████▋                     | 79/160 [32:40<41:18, 30.60s/it]question: 130, turn: 1, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1')\n",
      " 50%|█████████████████████                     | 80/160 [33:27<47:34, 35.68s/it]question: 81, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 51%|█████████████████████▎                    | 81/160 [33:55<43:40, 33.17s/it]question: 82, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 51%|█████████████████████▌                    | 82/160 [34:14<37:53, 29.15s/it]question: 83, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 52%|█████████████████████▊                    | 83/160 [34:37<35:05, 27.35s/it]question: 84, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 52%|██████████████████████                    | 84/160 [35:04<34:14, 27.04s/it]question: 85, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 53%|██████████████████████▎                   | 85/160 [35:40<37:15, 29.81s/it]question: 86, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 54%|██████████████████████▌                   | 86/160 [36:15<38:42, 31.39s/it]question: 87, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 54%|██████████████████████▊                   | 87/160 [36:28<31:36, 25.98s/it]question: 88, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 55%|███████████████████████                   | 88/160 [36:47<28:39, 23.89s/it]question: 89, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 56%|███████████████████████▎                  | 89/160 [37:04<25:47, 21.80s/it]question: 90, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 56%|███████████████████████▋                  | 90/160 [37:24<24:40, 21.15s/it]question: 91, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 57%|███████████████████████▉                  | 91/160 [37:40<22:28, 19.54s/it]question: 92, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 57%|████████████████████████▏                 | 92/160 [38:02<22:53, 20.20s/it]question: 93, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 58%|████████████████████████▍                 | 93/160 [38:27<24:25, 21.88s/it]question: 94, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 59%|████████████████████████▋                 | 94/160 [39:06<29:32, 26.86s/it]question: 95, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 59%|████████████████████████▉                 | 95/160 [39:47<33:45, 31.16s/it]question: 96, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 60%|█████████████████████████▏                | 96/160 [40:15<32:09, 30.15s/it]question: 97, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 61%|█████████████████████████▍                | 97/160 [40:32<27:41, 26.37s/it]question: 98, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 61%|█████████████████████████▋                | 98/160 [40:59<27:16, 26.40s/it]question: 99, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 62%|█████████████████████████▉                | 99/160 [41:21<25:31, 25.11s/it]question: 100, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 62%|█████████████████████████▋               | 100/160 [41:35<21:49, 21.83s/it]question: 131, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 63%|█████████████████████████▉               | 101/160 [41:50<19:28, 19.81s/it]question: 132, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 64%|██████████████████████████▏              | 102/160 [42:19<21:41, 22.43s/it]question: 133, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 64%|██████████████████████████▍              | 103/160 [42:38<20:15, 21.33s/it]question: 134, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 65%|██████████████████████████▋              | 104/160 [43:08<22:22, 23.97s/it]question: 135, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 66%|██████████████████████████▉              | 105/160 [43:28<20:53, 22.79s/it]question: 136, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 66%|███████████████████████████▏             | 106/160 [44:02<23:33, 26.18s/it]question: 137, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 67%|███████████████████████████▍             | 107/160 [44:22<21:25, 24.26s/it]question: 138, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 68%|███████████████████████████▋             | 108/160 [44:36<18:35, 21.45s/it]question: 139, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 68%|███████████████████████████▉             | 109/160 [45:10<21:23, 25.16s/it]question: 140, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 69%|████████████████████████████▏            | 110/160 [45:48<24:02, 28.84s/it]question: 141, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 69%|████████████████████████████▍            | 111/160 [46:14<22:51, 27.99s/it]question: 142, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 70%|████████████████████████████▋            | 112/160 [46:46<23:20, 29.18s/it]question: 143, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 71%|████████████████████████████▉            | 113/160 [47:20<23:57, 30.58s/it]question: 144, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 71%|█████████████████████████████▏           | 114/160 [47:39<20:51, 27.20s/it]question: 145, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 72%|█████████████████████████████▍           | 115/160 [48:09<21:04, 28.10s/it]question: 146, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 72%|█████████████████████████████▋           | 116/160 [48:43<21:47, 29.72s/it]question: 147, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 73%|█████████████████████████████▉           | 117/160 [49:07<20:09, 28.13s/it]question: 148, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 74%|██████████████████████████████▏          | 118/160 [49:32<19:00, 27.16s/it]question: 149, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 74%|██████████████████████████████▍          | 119/160 [49:52<17:06, 25.05s/it]question: 150, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 75%|██████████████████████████████▊          | 120/160 [50:35<20:13, 30.34s/it]question: 151, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 76%|███████████████████████████████          | 121/160 [51:11<20:58, 32.28s/it]question: 152, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 76%|███████████████████████████████▎         | 122/160 [51:36<18:54, 29.87s/it]question: 153, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 77%|███████████████████████████████▌         | 123/160 [51:53<16:06, 26.13s/it]question: 154, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 78%|███████████████████████████████▊         | 124/160 [52:20<15:45, 26.27s/it]question: 155, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 78%|████████████████████████████████         | 125/160 [52:41<14:31, 24.89s/it]question: 156, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 79%|████████████████████████████████▎        | 126/160 [53:27<17:32, 30.96s/it]question: 157, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 79%|████████████████████████████████▌        | 127/160 [53:59<17:17, 31.43s/it]question: 158, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 80%|████████████████████████████████▊        | 128/160 [54:28<16:26, 30.83s/it]question: 159, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 81%|█████████████████████████████████        | 129/160 [55:16<18:33, 35.90s/it]question: 160, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-v2-multi-turn')\n",
      " 81%|█████████████████████████████████▎       | 130/160 [55:31<14:50, 29.68s/it]question: 101, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▌       | 131/160 [56:01<14:22, 29.75s/it]question: 102, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▊       | 132/160 [56:24<12:56, 27.74s/it]question: 103, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 83%|██████████████████████████████████       | 133/160 [56:52<12:24, 27.57s/it]question: 104, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▎      | 134/160 [57:07<10:21, 23.90s/it]question: 105, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▌      | 135/160 [57:37<10:47, 25.92s/it]question: 106, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 85%|██████████████████████████████████▊      | 136/160 [57:54<09:11, 22.96s/it]question: 107, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████      | 137/160 [58:16<08:46, 22.90s/it]question: 108, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████▎     | 138/160 [58:48<09:22, 25.55s/it]question: 109, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 87%|███████████████████████████████████▌     | 139/160 [59:09<08:29, 24.27s/it]question: 110, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 88%|███████████████████████████████████▉     | 140/160 [59:27<07:28, 22.41s/it]question: 111, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 88%|██████████████████████████████████▎    | 141/160 [1:00:03<08:21, 26.39s/it]question: 112, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 89%|██████████████████████████████████▌    | 142/160 [1:00:27<07:42, 25.68s/it]question: 113, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 89%|██████████████████████████████████▊    | 143/160 [1:00:43<06:26, 22.75s/it]question: 114, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 90%|███████████████████████████████████    | 144/160 [1:01:19<07:08, 26.81s/it]question: 115, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 91%|███████████████████████████████████▎   | 145/160 [1:01:44<06:31, 26.08s/it]question: 116, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 91%|███████████████████████████████████▌   | 146/160 [1:02:11<06:09, 26.40s/it]question: 117, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 92%|███████████████████████████████████▊   | 147/160 [1:02:28<05:06, 23.60s/it]question: 118, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 92%|████████████████████████████████████   | 148/160 [1:03:06<05:36, 28.05s/it]question: 119, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_1, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 93%|████████████████████████████████████▎  | 149/160 [1:03:21<04:25, 24.11s/it]question: 120, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 94%|████████████████████████████████████▌  | 150/160 [1:03:52<04:21, 26.17s/it]question: 121, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: model_2, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 94%|████████████████████████████████████▊  | 151/160 [1:04:26<04:16, 28.49s/it]question: 122, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 95%|█████████████████████████████████████  | 152/160 [1:04:57<03:54, 29.27s/it]question: 123, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_2, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 96%|█████████████████████████████████████▎ | 153/160 [1:05:14<02:58, 25.54s/it]question: 124, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 96%|█████████████████████████████████████▌ | 154/160 [1:05:39<02:32, 25.48s/it]question: 125, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 97%|█████████████████████████████████████▊ | 155/160 [1:05:59<01:58, 23.73s/it]question: 126, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 98%|██████████████████████████████████████ | 156/160 [1:06:24<01:36, 24.05s/it]question: 127, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 98%|██████████████████████████████████████▎| 157/160 [1:06:55<01:18, 26.28s/it]question: 128, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 99%|██████████████████████████████████████▌| 158/160 [1:07:28<00:56, 28.28s/it]question: 129, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: tie, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      " 99%|██████████████████████████████████████▊| 159/160 [1:07:59<00:29, 29.10s/it]question: 130, turn: 2, model_1: mistral-dolphin-dpo, model_2: mistral-dolphin-sft, g1_winner: tie, g2_winner: model_1, judge: ('gpt-4-1106-preview', 'pair-math-v1-multi-turn')\n",
      "100%|███████████████████████████████████████| 160/160 [1:08:26<00:00, 25.67s/it]\n"
     ]
    }
   ],
   "source": [
    "open_ai_key=\"sk-xxx\" # replace with your openai key\n",
    "\n",
    "# Pairwise comparison of the two models using OpenAI's GPT-4 Turbo\n",
    "!OPENAI_API_KEY={open_ai_key} python gen_judgment.py --model-list \"mistral-dolphin-dpo\" \"mistral-dolphin-sft\" --judge-model \"gpt-4-1106-preview\" --mode \"pairwise-all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f3c092-ed6a-4037-9117-b9669dc7119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.1 pytz-2024.1 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fed7045-5a32-4ac2-beaf-d999e1d5902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d3c532-62c8-4721-8ed9-5cadc9fc37b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: pairwise-all\n",
      "Input file: ./data/mt_bench/model_judgment/gpt-4-1106-preview_pair.jsonl\n",
      "| model               |   win |   loss |   tie |   win_rate |   loss_rate |   win_rate_adjusted |\n",
      "|:--------------------|------:|-------:|------:|-----------:|------------:|--------------------:|\n",
      "| mistral-dolphin-sft |    39 |     19 |   144 |  0.193069  |   0.0940594 |            0.549505 |\n",
      "| mistral-dolphin-dpo |    19 |     39 |   144 |  0.0940594 |   0.193069  |            0.450495 |\n"
     ]
    }
   ],
   "source": [
    "# Results are saved at the following location, make sure its correct\n",
    "res = \"./data/mt_bench/model_judgment/gpt-4-1106-preview_pair.jsonl\"\n",
    "\n",
    "!python show_result.py --input-file {res} --model-list \"mistral-dolphin-dpo\" \"mistral-dolphin-sft\" --judge-model \"gpt-4-1106-preview\" --mode pairwise-all\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753996fc-4bf3-44d1-ab00-495b707cb63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display plot from image file\n",
    "from PIL import Image\n",
    "i = Image.open(\"win_rate_gpt-4-1106-preview.png\")\n",
    "i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688b859-709f-4cc0-aa66-e3a18c0cd10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
